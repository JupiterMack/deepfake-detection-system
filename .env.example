# -----------------------------------------------------------------------------
# Deepfake Detection System - Environment Variables
#
# Instructions:
# 1. Copy this file to a new file named .env
# 2. Fill in the values for your specific environment.
# 3. The .env file is ignored by git, so your secrets are safe.
# -----------------------------------------------------------------------------

# --- Application & API Configuration ---
# The host and port for the web API server.
# Use 0.0.0.0 to make the server accessible on your network.
API_HOST=0.0.0.0
API_PORT=8000

# Logging level (e.g., DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# --- Model Configuration ---
# Path to the pre-trained deepfake detection model file.
MODEL_PATH=models/default_model.pth

# Specify the device for PyTorch to use ('cuda' for GPU, 'cpu' for CPU).
# Set to 'auto' to let the application decide.
DEVICE=auto

# --- Data & Output Paths ---
# Path to the root directory of the dataset (for training/evaluation scripts).
DATASET_PATH=data/

# Directory to save output files, such as processed images, reports, or XAI visualizations.
OUTPUT_DIR=output/

# --- Training Hyperparameters (Optional - for training scripts) ---
# These are typically used when running training scripts.
LEARNING_RATE=0.001
BATCH_SIZE=32
NUM_EPOCHS=10

# --- Explainable AI (XAI) Configuration ---
# The Captum method to use for generating explanations (e.g., IntegratedGradients, GradCAM, Occlusion).
XAI_METHOD=IntegratedGradients